{
  "metadata": {
    "name": "stock_comment",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# About Dataset\nOriginally we were planning to scrap conversation data from [Yahoo finance](https://finance.yahoo.com/quote/AA/community). The conversation data is recent and diverse. But web-scrapping consumes a lot of time. After 20 hours running on local machine, only about 30MB of data has been generated. I also tried to run the script on a CIMS server, but Google chrome runs very slowly inside the virtual box. Thus, considering time and data size, I obtained the Stockwits dataset(about 194.3MB) collected by an Udacity Team as an alternative option. The dataset contains messages from Stockwits(a social media app), and those messages are similar to posts on twitter. This dataset is available in the pulic domain and contains sufficient data. More detailed description can be found [here](https://vkontech.com/sentiment-analysis-of-stocktwits-messages-using-lstm-in-pytorch/). "
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": " \n# Exploratory data analysis \u0026 cleansing\nHere, I created a schema for the dataframe, called z.show() to present some rows of the dataset. In total, there are 4 columns, 1548010 rows. Column names and types are shown in the printSchema output."
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"project/comments.csv\"\nval schema \u003d \"index STRING, message_body STRING, sentiment INT, timestamp TIMESTAMP\"\nval rawDF \u003d spark.read.schema(schema)\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\nz.show(rawDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "rawDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath2 \u003d \"project/output.csv\""
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val rawDF2 \u003d spark.read.csv(filePath2)\nval filtered \u003d rawDF2.filter(rawDF2(\"_c1\") \u003d!\u003d \"Symbols\").cache()\nz.show(filtered)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "filtered.printSchema\n"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val joinedDF \u003d rawDF.join(broadcast(filtered), rawDF(\"index\") \u003d\u003d\u003d filtered(\"_c0\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(joinedDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "joinedDF.printSchema"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val newDF \u003d joinedDF.select($\"index\", $\"message_body\", $\"sentiment\", $\"timestamp\", split(col(\"_c1\"),\",\").alias(\"list_of_stocks\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(newDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import scala.collection.mutable.WrappedArray\nval convert_list \u003d udf((values: WrappedArray[String])\u003d\u003e {\n    values.toList})\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val converted \u003d newDF.withColumn(\"list_of_symbols\", convert_list(col(\"list_of_stocks\")))\n                    .withColumn(\"index\", col(\"index\"))\n                    .withColumn(\"message_body\", col(\"message_body\"))\n                    .withColumn(\"sentiment\", col(\"sentiment\"))\n                    .withColumn(\"timestamp\", col(\"timestamp\"))\nz.show(converted)"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val flatted \u003d converted.select($\"list_of_symbols\",$\"index\", $\"message_body\", $\"sentiment\", to_date($\"timestamp\").alias(\"timestamp\"), explode($\"list_of_symbols\").alias(\"flatted_symbol\"))\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(flatted)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val groupedDF \u003d flatted.groupBy(\"flatted_symbol\", \"timestamp\").agg(avg(\"sentiment\"))\nz.show(groupedDF)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val removeDF \u003d groupedDF\n                .withColumn(\"flatted_symbol\", regexp_replace(col(\"flatted_symbol\"), \"\\\\$\", \"\"))\nz.show(removeDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val dfWithWeekNumber \u003d removeDF.withColumn(\"dayOfWeek\", date_format(col(\"timestamp\"), \"E\"))\nval df4 \u003d dfWithWeekNumber.withColumn(\"shiftedDate\", when( col(\"dayOfWeek\") \u003d\u003d\u003d \"Sat\", date_add(col(\"timestamp\"),2))\n.when(col(\"dayOfWeek\") \u003d\u003d\u003d \"Sun\", date_add(col(\"timestamp\"),1))\n.otherwise(col(\"timestamp\")))\nz.show(df4)"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val nflx \u003d df4.filter(col(\"flatted_symbol\") \u003d\u003d\u003d \"NFLX\").select(col(\"shiftedDate\"), col(\"avg(sentiment)\")).sort(col(\"shiftedDate\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(nflx)"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// val finalDF \u003d nflx.withColumn(\"date\", to_date($\"shiftedDate\"))\n//                 .withColumn(\"flatted_symbol\", $\"flatted_symbol\")\n//                 .withColumn(\"sentiment\", $\"avg(sentiment)\")\n//                 .withColumn(\"dayOfWeek\", $\"flatted_symbol\")\n//                 .withColumn(\"flatted_symbol\", $\"flatted_symbol\")"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(nflx)"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "rawDF.columns.length"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val TSLA \u003d df4.filter(col(\"flatted_symbol\") \u003d\u003d\u003d \"TSLA\").select(col(\"shiftedDate\"), col(\"avg(sentiment)\")).sort(col(\"shiftedDate\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "z.show(TSLA)"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val outputPath \u003d \"project/cleanedComments.csv\"\ndf4.write.mode(\"overwrite\").csv(outputPath)\n"
    }
  ]
}